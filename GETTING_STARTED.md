# Minimal YOLOv5 - Complete Package

## ğŸ“¦ What You Got

A minimal, educational implementation of YOLOv5 with ~7,000 parameters that teaches you how to build object detection from scratch.

## ğŸ“ Files Included

1. **minimal_yolov5.py** (Main Implementation)
   - Core YOLOv5 model architecture
   - Building blocks: Conv, C3, SPPF, Detect
   - Loss function implementation
   - Simple training loop example
   - ~500 lines of well-commented code

2. **train_yolov5.py** (Complete Training Script)
   - Data loading in YOLO format
   - Letterbox preprocessing
   - Full training loop with validation
   - Checkpointing and early stopping
   - Visualization utilities
   - Inference function

3. **config.yaml** (Configuration File)
   - Training hyperparameters
   - Dataset paths
   - Model settings
   - Easy to customize

4. **README.md** (Documentation)
   - Architecture overview
   - Quick start guide
   - Detailed component explanations
   - Training tips
   - Customization guide
   - Debugging tips

5. **examples.py** (Learning Examples)
   - 7 hands-on examples
   - Model creation
   - Forward pass
   - Loss computation
   - Training step
   - Inference
   - Feature visualization

6. **explain_letterbox.py** (Letterbox Tutorial)
   - Visual explanation of letterbox resizing
   - Step-by-step code walkthrough
   - Why it's necessary
   - Label adjustment math
   - Multiple aspect ratio examples

## ğŸ¯ Key Features

### Simplified from Full YOLOv5
- **Removed**: Complex data augmentation, distributed training, TTA, anchor optimization
- **Kept**: Core architecture, detection logic, loss computation, essential training
- **Result**: Easy to understand while maintaining YOLOv5's essence

### Educational Focus
- Extensive comments explaining each component
- Visual diagrams and explanations
- Step-by-step tutorials
- Real working code you can run

### Production-Ready Structure
- Proper model architecture
- Complete training pipeline
- Checkpointing and validation
- Configurable hyperparameters

## ğŸš€ Quick Start

### 1. Test the Model
```python
from minimal_yolov5 import YOLOv5
import torch

model = YOLOv5(num_classes=80, channels=3)
x = torch.randn(1, 3, 640, 640)
output = model(x)
print(f"Output shape: {output.shape}")  # (1, 25200, 85)
```

### 2. Run Examples
```bash
python examples.py
```

This will show you:
- How to create the model
- How forward pass works
- How loss is computed
- How to train for one step
- How inference works
- How to visualize features

### 3. Prepare Your Dataset

Structure:
```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img3.jpg
â”‚       â””â”€â”€ img4.jpg
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ img1.txt
    â”‚   â””â”€â”€ img2.txt
    â””â”€â”€ val/
        â”œâ”€â”€ img3.txt
        â””â”€â”€ img4.txt
```

Label format (one object per line):
```
class_id x_center y_center width height
```
All coordinates normalized to [0, 1].

### 4. Configure Training

Edit `config.yaml`:
```yaml
train_img_dir: 'your/path/to/train/images'
train_label_dir: 'your/path/to/train/labels'
val_img_dir: 'your/path/to/val/images'
val_label_dir: 'your/path/to/val/labels'

num_classes: 80  # Change to your number
batch_size: 16   # Adjust for your GPU
epochs: 100
```

### 5. Train
```bash
python train_yolov5.py --config config.yaml --mode train
```

### 6. Inference
```bash
python train_yolov5.py --mode detect --weights runs/train/exp/best.pt --source image.jpg
```

## ğŸ“Š Model Architecture

```
Input (640Ã—640Ã—3)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKBONE       â”‚
â”‚  CSPDarknet53   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv + C3       â”‚ â†’ P3 (80Ã—80Ã—128)   Small objects
â”‚ Conv + C3       â”‚ â†’ P4 (40Ã—40Ã—256)   Medium objects
â”‚ Conv + C3 + SPPFâ”‚ â†’ P5 (20Ã—20Ã—512)   Large objects
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NECK           â”‚
â”‚  PANet          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Upsampling      â”‚
â”‚ Feature Fusion  â”‚
â”‚ Downsampling    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HEAD           â”‚
â”‚  Detect         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3 scales        â”‚
â”‚ 3 anchors each  â”‚
â”‚ â†’ 25,200 preds  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Key Concepts Explained

### 1. Letterbox Resizing

**Problem**: Images come in different sizes, but neural networks need fixed input.

**Solution**: Letterbox resizing
- Scales image to fit in target size
- Maintains aspect ratio (no distortion)
- Adds gray padding to make it square

**Label Adjustment**:
```python
# Scale coordinates
labels[:, 1] = ratio * labels[:, 1] + dw / img_size
labels[:, 2] = ratio * labels[:, 2] + dh / img_size
labels[:, 3] *= ratio
labels[:, 4] *= ratio
```

**Why?** The padding shifts object positions, so we must shift the labels to match!

See `explain_letterbox.py` for visual explanation.

### 2. Anchor-Based Detection

YOLO uses **anchor boxes** - predefined box shapes at each grid cell:
- Small anchors for small objects
- Medium anchors for medium objects
- Large anchors for large objects

The model predicts **offsets** from these anchors, not absolute coordinates.

### 3. Multi-Scale Detection

YOLO detects objects at 3 different scales:
- **P3 (80Ã—80)**: Small objects (people far away, small items)
- **P4 (40Ã—40)**: Medium objects (cars, furniture)
- **P5 (20Ã—20)**: Large objects (buses, buildings)

This allows detecting objects of all sizes in one pass!

### 4. Loss Function

Three components:
1. **Box Loss** (IoU): How well boxes match ground truth
2. **Objectness Loss**: Whether a grid cell contains an object
3. **Classification Loss**: What class the object is

Total loss = box_loss + obj_loss + cls_loss

## ğŸ’¡ Training Tips

### For Small Datasets (<1000 images)
```yaml
epochs: 50
batch_size: 8
lr: 0.001
```

### For Medium Datasets (1000-10000 images)
```yaml
epochs: 100
batch_size: 16
lr: 0.01
```

### GPU Memory Issues?
- Reduce `batch_size` to 8 or 4
- Reduce `img_size` to 416
- Close other applications

### Model Not Learning?
1. Check data loading - print batch shapes
2. Verify loss decreasing - check training history
3. Visualize predictions - are they getting better?
4. Try lower learning rate

## ğŸ› ï¸ Customization

### Change Number of Classes
```python
model = YOLOv5(num_classes=YOUR_NUM, channels=3)
```

### Modify Architecture Depth
```python
# In YOLOv5.__init__()
self.c3_3 = C3(256, 256, num_blocks=5)  # More blocks = deeper
```

### Change Channel Widths
```python
# In YOLOv5.__init__()
self.conv4 = Conv(128, 384, 3, 2)  # 256â†’384 channels
```

### Add Data Augmentation
```python
# In YOLODataset.__getitem__()
if self.augment:
    img = random_flip(img)
    img = random_brightness(img)
    img = random_crop(img)
```

## ğŸ“ˆ What's Simplified

Compared to full YOLOv5, this minimal version doesn't include:
- Mosaic augmentation
- Automatic anchor optimization  
- Mixed precision training
- Model ensembling
- Test-time augmentation
- Multi-GPU training
- Advanced learning rate schedules
- Exponential moving average (EMA)

These are important for state-of-the-art performance, but not essential for learning!

## ğŸ“ Learning Path

1. **Beginner**: 
   - Run examples.py
   - Understand forward pass
   - Read architecture code

2. **Intermediate**:
   - Train on a small dataset
   - Modify architecture
   - Experiment with hyperparameters

3. **Advanced**:
   - Implement new loss functions
   - Add data augmentation
   - Optimize for speed

4. **Expert**:
   - Add missing features from full YOLOv5
   - Implement YOLOv8 improvements
   - Create custom architectures

## ğŸ› Common Issues

### Issue: "CUDA out of memory"
**Solution**: Reduce batch_size in config.yaml

### Issue: Loss is NaN
**Solution**: 
- Lower learning rate
- Check for bad labels
- Ensure images load correctly

### Issue: No detections
**Solution**:
- Train longer (more epochs)
- Check confidence threshold
- Visualize training progress

### Issue: Poor accuracy
**Solution**:
- More training data
- Better data quality
- Data augmentation
- Longer training

## ğŸ“š Further Learning

1. **Papers**:
   - YOLOv5 by Ultralytics
   - CSPNet: Cross Stage Partial Network
   - PANet: Path Aggregation Network

2. **Concepts**:
   - Object detection fundamentals
   - Convolutional neural networks
   - Anchor-based detection
   - Feature pyramids

3. **Advanced Topics**:
   - Attention mechanisms
   - Transformer-based detection
   - Self-supervised learning
   - Knowledge distillation

## âš¡ Performance Expectations

With this minimal implementation:
- **Speed**: ~30-50 FPS on GPU (depending on hardware)
- **Accuracy**: Lower than full YOLOv5 (no advanced augmentations)
- **Model Size**: ~28 MB (7M parameters)

For production use, consider the full YOLOv5 or YOLOv8 implementation.

## ğŸ¤ Next Steps

1. Run all examples to understand each component
2. Train on a small dataset (100-500 images)
3. Visualize predictions and understand errors
4. Modify architecture and experiment
5. Implement one missing feature (e.g., mosaic augmentation)
6. Compare with full YOLOv5

## ğŸ“ Files Summary

| File | Purpose | Lines | Difficulty |
|------|---------|-------|------------|
| minimal_yolov5.py | Core model | ~500 | â­â­â­ |
| train_yolov5.py | Training pipeline | ~600 | â­â­ |
| config.yaml | Configuration | ~20 | â­ |
| README.md | Documentation | ~300 | â­ |
| examples.py | Tutorials | ~400 | â­â­ |
| explain_letterbox.py | Visual guide | ~400 | â­ |

## ğŸ¯ Success Criteria

You'll know you understand YOLOv5 when you can:
- âœ… Explain the three-part architecture
- âœ… Trace a forward pass through the model
- âœ… Understand why letterbox resizing is needed
- âœ… Compute the loss for a sample
- âœ… Train a model on custom data
- âœ… Modify the architecture confidently

---

**Happy Learning! ğŸš€**

Questions? Read the detailed README.md or check the examples!
